<h1>Building a custom EukDetect database</h1>

The process to generate a database is as follows:
- identify candidate genes in genomes of interest using BUSCO
- Cluster genes at >97% identity
- Cluster genes at >99% identity & identify species to remove, if any
- mask repetitive regions in genes
- remove genes that are highly masked or size outliers
- build alignment database from input fasta of genes
- create the following precomputed database files for eukdetect: `specific_and_inherited_markers_per_taxid.txt`, `busco_taxid_link.txt`, and `taxid_cumulativelength.txt`.
- store NCBI taxonomy database release to for ete3
- ideally, sanity check this database for any problematic markers by running the EukDetect pipeline with either real or simulated microbiome sequencing data.


More info on every step of this is below.


Requirements:
- accessory scripts in the eukdetect/build_db folder (the following instructions assume you have added this directory to your path. if not, run scripts by specifying absolute paths)
- biopython
- busco>=5.4.0 (I run this through a container, though conda install also works fine)
- cd-hit-est>=v4.8.1
- repeatmasker (I run RepeatMasker through the dfam-tetools container: https://github.com/Dfam-consortium/TETools)
- bedtools

<h2>Identifying candidate genes in genomes of interest</h2>
<h3>Run BUSCO</h3>
Gather genomes desired for database. Important note is that there can only be one genome representing a species taxID in the database. Keep track of species names and corresponding NCBI taxonomy IDs, as this is necessary for later in the database construction process. Also, at the same time as you download genomes and make a note of species ID - taxonomy ID correspondence, download the NCBI taxonomy database (taxdump.tar.gz at https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/). You will want to save this version of the taxonomy database so that all compute will be done with this.

Run busco with a version greater than 5.4.0 on each genome, using Augustus instead of metaeuk, using a command similar to the following: 

`busco --lineage_dataset /path/to/eukaryota_odb10 -m geno -f --long --offline -i $genome -o $outdir/busco/ --augustus --long`

<h3>Extract BUSCO DNA sequences from genomes</h3>
The BUSCO pipeline is designed to output both DNA and protein fastas of the identified protein files. However, I have had issues with this, so I manually extract the buscos from the genome using bedtools. This process also assigns an informative name to each busco. The helper script for this step is `extract_buscos_from_genome_and_fulltable.py`, which will generate a bed file for each genome. `bedtools getfasta` is then run on each bedfile/genome pair to generate a BUSCO file with informative names.

For all the genomes you are interested in, create a tab delimited table that is structured as follows:
|Tab1|Tab2|Tab3|Tab4|Tab5|
|----|----|---|----|----|
|Species_name|prefix|/path/to/genome.fasta|/path/to/buscodir/run_eukaryota_odb10/full_table.tsv|/path/to/busco_output.txt|

The file in Tab 4 is the full path to the `full_table.tsv` output generated by BUSCO, and the file in tab 5 is the full path to an output file that will contain the BUSCO bedfile for that particular genome.

Then, run `python table_to_bed.py [input_table]` to generate each bedfile.

For each bed file/genome pair, run the following command:

`bedtools getfasta -nameOnly -s -fi [genome.fasta] -bed [buscos.bed] | perl -pi -e 's/\(.\)//' > [buscos_dna.fasta]`

Then, concatenate all `buscos_dna.fasta` files together and move to clustering genes. Remove sequences that correspond to BUSCO genes that can be predicted in bacterial genomes with the following two commands:

`grep -f bact_buscos.txt buscos_dna.fasta | cut -f 2 -d ">" > bact_buscos_to_remove.txt`

`remove_seqs_from_fasta.py bact_buscos_to_remove.txt buscos_dna.fasta > buscos_dna_nobact.fasta`

<h2>Clustering genes at >99% identity</h2>

<h3>Identifying species groups and choosing a representative</h3>

Read aligment based methods are not designed to distinguish very similar genomes from each other. When there are multiple species with identical or nearly identical genomes, EukDetect will not be able to distinguish between them. When building the database, genes that are >99% identical are collapsed either at the species level, the genus level, or are designated "multigenus_collapse". This can sometimes mask species that are important to present: for example, hybrids of S. cerevisiae present in the NCBI genome database are removed from the EukDetect database to prevent a genus-level collapse of the informativeness of S. cerevisiae genes.

To determine whether you want to remove any of your genomes before proceeding, in this step we identify groups of species that are too similar to distinguish. The first step is to run cd-hit, and then run several accessory scripts that parse the cd-hit output.

`cd-hit-est -d 0 -i [buscos.fasta] -o buscos_cdhit99.fasta -c 0.99 -T [threads] -M [memory]`

This creates the output files `busco_cdhit99.fasta`, with one single representative for each cd-hit cluster, and `busco_cdhit99.fasta.clstr`, which includes information from cd-hit about which genes went into each cluster. The following command removes all single-gene clusters:

`get_spcluster_from_cdhit.py buscos_cdhit99.fasta.clstr > buscos_cdhit99_spclusters.txt`

To parse this into a readable format that is used by downstream parts of the eukdetect database creation pipeline, run:

`count_same_species_clusters_and_remove_multigroup.py buscos_cdhit99_spclusters.txt > buscos_cdhit99_cluster_list.txt`

This step will also discard genes that are clustering at >99% identity across different prefix groups, implying there is an error in their taxonomic assignment. Information about discarded genes is in `buscos_cdhit99_spcluster_removed_for_multigroup.txt`. If the file is empty, nothing was discarded.

Finally, to create a human-readable table that tells you the number of collapsed genes per species and which species it overlaps with, run:

`count_grouped_genes.py buscos.fasta buscos_cdhit99_cluster_list.txt > buscos_cdhit99_collapsed_counts_info.txt`

Look through the output of the final table and determine whether you would like to remove any species from downstream analyses. If so, remove genes belonging to those species from the fasta file, and re-run all previous steps in clustering.

Once you have removed the species you want to remove, you will now rename the cd-hit clustered genes with informative names. The options are _SSCollapse (clustered genes are all from the same species), _SPCollapse (clustered genes are all from the same genus), and _MGCollapse (clustered genes are from multiple genuses).

`rename_cdhit_collapsed.py buscos_rmsp_cdhit99_cluster_list.txt buscos_rmsp_cdhit99.fasta > buscos_rmsp_cdhit99_renamed.fasta`

This script will also produce the file `buscos_rmsp_cdhit99_collapsed_seqnames.txt`, which will be needed in a later step of database construction to assign taxonomy IDs to genes.

<h2>Masking clustered database</h2>
Once the database has been clustered, we use RepeatMasker to mask repetitive sequences in the database. This is done to reduce the likelihood of low complexity reads being considered as informative by eukdetect. Since the goal is to mask low complexity areas and not identify transposable elements, we use hard masking and don't specify a specific species.

RepeatMasker requries short fasta headers, and to keep the gene names informative the eukdetect database fasta headers are long. For this step, we temporarily rename the headers, which we'll restore after the RepeatMasker run. There is a helper set of scripts for this - all this is doing is renaming the fasta headers.

`rename_buscos_sequential_for_rpmasker.py buscos_rmsp_cdhit99_renamed.fasta > buscos_rmsp_cdhit99_renamed_simplename.fasta`

This command also will generate the file `busco_rmsp_cdhit99_renamed_busco_seqid_sequential_correspondence.txt` (needed for renaming sequences post-masking).

Then, run RepeatMasker (if you're using the dfam container, this will need to be wrapped with the apptainer exec commands):

`RepeatMasker -pa [threads] -qq -noint -norna -dir . buscos_rmsp_cdhit99_renamed_simplename.fasta`

After RepeatMasker has finished you can rename the masked fasta with the following helper script:

`rename_after_rpmasker.py busco_rmsp_cdhit99_renamed_busco_seqid_sequential_correspondence.txt buscos_rmsp_cdhit99_renamed_simplename.fasta.masked > buscos_rmsp_cdhit99_renamed_allmasked.fasta`

We then remove sequences that are >10% masked:

`remove_masked_above_10percent.py buscos_rmsp_cdhit99_renamed_allmasked.fasta > buscos_rmsp_cdhit99_renamed_masked.fasta`

This script will write the names of all removed sequences to a separate file - if you're targeting a particular species, you might want to look at this file and make sure lots of sequences haven't been removed from a species of interest.

<h2>Build alignment database</h2>
Build bowtie2 alignment database.

`bowtie2-build buscos_rmsp_cdhit99_renamed_masked.fasta all_buscos --threads [threadcount]`

Depending on the size of the database, you may need to add the `--large-index` option (this is true for the default EukDetect database, ~6 Gb of sequence).

<h2>Creating pre-computed files for eukdetect</h2>

There are three files to generate that store information for eukdetect. They are: `busco_taxid_link.txt`, `specific_and_inherited_markers_per_taxid.txt`, and `taxid_cumulativelength.txt`.

`busco_taxid_link.txt` is a tab separated file with each gene name and the corresponding taxid. To generate this, you will need a tab delimited file with all of the species names and their corresponding taxids and the output `buscos_rmsp_cdhit99_collapsed_seqnames.txt` from the `rename_cdhit_collapsed.py` script.

If you have not yet set up an ete3 database, or you have but it's for a different version of the NCBI taxonomy database you're building the busco database from, run the command

`init_ete3_ncbitaxa.py --taxdump /path/to/taxdump.tar.gz --dbpath /path/to/store/database/`

Ete3 reads and writes, by default, its taxonomy database in `~/.etetoolkit/'. I have not found a way to change where it initially writes this database, but you can move it and then pass it to ete3 from a different location. This script will check to see if you have any databases currently in the .etetoolkit directory, move them to a temporary directory, initialize ete3 with your taxdump.tar.gz file, move the new database to the directory you specify, and then restore the original taxa.sqlite database files. This will save your existing ete3 setup, if you have one.

After you initialize the ete3 database, you should run the following script: 

`get_uncomputed_taxid_per_busco.py --speciestax species_taxids.txt --fasta buscos_rmsp_cdhit99_renamed_masked.fasta --collapsed_ids buscos_cdhit99_collapsed_seqnames.txt --taxdb /path/to/taxa.sqlite > busco_taxid_link.txt`

Warning - depending on how many collapsed sequences you have, this is slow. a tree is built for all species corresponding to a collapsed sequence and the root inferred.

To generate the `specific_and_inherited_markers_per_taxid.txt` file, run the following command:

`get_specific_and_inherited_markers.py busco_taxid_link.txt /path/to/taxa.sqlite `

This script will also be slow if you are running this on a large dataset.

Finally, create the `taxid_cumulativelength.txt` file:

`sum_buscolens_per_taxid.py buscos_rmsp_cdhit99_renamed_masked.fasta busco_taxid_link.txt > taxid_cumulativelength.txt`

<h2>Optional but strongly recommended: run simulated and real datasets against EukDetect database, screen for possible bacterial genes</h2>

Despite the controls here to eliminate bacterial contamination, some can still sneak in. Before I use a new database, I like to align a lot of reads both simulated from bacterial genomes and real microbiome sequencing datasets to identify and remove any sequences that seem wonky. Wonky here means - many reads aligning to one gene, usually in a small portion of the gene, and no other genes from that species having hits. Basically, any kind of outlier. How you do this will be up to you and the compute power you can access. 

My favorite way to do this is simulate reads from the [GEM metagenome catalogue](https://www.nature.com/articles/s41587-020-0718-6) with [InSilicoSeq](https://github.com/HadrienG/InSilicoSeq) and align against the new database. This will identify a pretty comprehensive list of potentially bacterial genes (though it has some false positives - some of these MAGs appear to be reverse-contaminated by Malassezia, a common skin fungus). This approach requires the most compute power, but is best if you're using the database to identify eukaryotes in an environmental sample, and also probably a good plan if you're using a non-human host-associated sample as well. Less intensive but still high throughput is to use the same approach but with the [UHGG database](https://www.nature.com/articles/s41587-020-0603-3).

<h2>Putting it all together: actually using the database for a eukdetect run</h2>

Instead of downloading and using the default EukDetect database, put all of the following files in a single folder and specify that as the location of the EukDetect database:

ETE3 database:
`taxa.sqlite`
`taxa.sqlite.traverse.pkl`

Pre-computed taxonomy files:
`busco_taxid_link.txt`
`specific_and_inherited_markers_per_taxid.txt`
`taxid_cumulativelength.txt`

Bowtie2 database:
`buscos_rmsp_cdhit99_renamed_masked.fasta`
`buscos_rmsp_cdhit99_renamed_masked.fasta.1.bt2l`
`buscos_rmsp_cdhit99_renamed_masked.fasta.2.bt2l`
`buscos_rmsp_cdhit99_renamed_masked.fasta.3.bt2l`
`buscos_rmsp_cdhit99_renamed_masked.fasta.4.bt2l`
`buscos_rmsp_cdhit99_renamed_masked.fasta.rev.1.bt2l`
`buscos_rmsp_cdhit99_renamed_masked.fasta.rev.2.bt2l`

Then, in the config file, give the path to this folder as both the `database_dir` and the `taxonomy_dir`, and `buscos_rmsp_cdhit99_renamed_masked.fasta` as the `database_prefix`. 

You can now run EukDetect with your custom database.
